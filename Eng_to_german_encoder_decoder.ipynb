{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import string\nimport re\nfrom numpy import array, argmax, random, take\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Embedding, RepeatVector\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import load_model\nfrom keras import optimizers\nimport matplotlib.pyplot as plt\n%matplotlib inline\npd.set_option('display.max_colwidth', 200)","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def read_text(filename):\n        # open the file\n        file = open(filename, mode='rt', encoding='utf-8')\n        \n        # read all text\n        text = file.read()\n        file.close()\n        return text","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata=read_text('../input/deu.txt')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_lines(text):\n      sents = text.strip().split('\\n')\n      sents = [i.split('\\t') for i in sents]\n      return sents","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deu_eng = to_lines(data)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deu_eng[:5]","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"[['Hi.', 'Hallo!'],\n ['Hi.', 'Grüß Gott!'],\n ['Run!', 'Lauf!'],\n ['Wow!', 'Potzdonner!'],\n ['Wow!', 'Donnerwetter!']]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"deu_eng = array(deu_eng)\ndeu_eng[:5]","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"array([['Hi.', 'Hallo!'],\n       ['Hi.', 'Grüß Gott!'],\n       ['Run!', 'Lauf!'],\n       ['Wow!', 'Potzdonner!'],\n       ['Wow!', 'Donnerwetter!']], dtype='<U537')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"deu_eng = deu_eng[:50000,:]","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\ndeu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]\ndeu_eng","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"array([['Hi', 'Hallo'],\n       ['Hi', 'Grüß Gott'],\n       ['Run', 'Lauf'],\n       ...,\n       ['The man died of cancer', 'Der Mann starb an Krebs'],\n       ['The man lay motionless', 'Der Mann lag bewegungslos da'],\n       ['The man must be insane', 'Der Mann muss geistesgestört sein']],\n      dtype='<U537')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(deu_eng)):\n    deu_eng[i,0] = deu_eng[i,0].lower()\n    deu_eng[i,1] = deu_eng[i,1].lower()\n","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deu_eng","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"array([['hi', 'hallo'],\n       ['hi', 'grüß gott'],\n       ['run', 'lauf'],\n       ...,\n       ['the man died of cancer', 'der mann starb an krebs'],\n       ['the man lay motionless', 'der mann lag bewegungslos da'],\n       ['the man must be insane', 'der mann muss geistesgestört sein']],\n      dtype='<U537')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"eng_l = []\ndeu_l = []\n\nfor i in deu_eng[:,0]:\n      eng_l.append(len(i.split()))\n\nfor i in deu_eng[:,1]:\n      deu_l.append(len(i.split()))","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t  = Tokenizer()\nfit_text = \"The earth is an awesome place live\"\na=t.fit_on_texts(fit_text)\ntest_text = \"The earth is an great place live\"\nsequences = t.texts_to_sequences(test_text)\nprint(sequences)\n","execution_count":13,"outputs":[{"output_type":"stream","text":"[[3], [4], [1], [], [1], [2], [8], [3], [4], [], [5], [6], [], [2], [9], [], [], [8], [1], [2], [3], [], [13], [7], [2], [14], [1], [], [7], [5], [15], [1]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenization(lines):\n      tokenizer = Tokenizer()\n      tokenizer.fit_on_texts(lines)\n      return tokenizer\neng_tokenizer = tokenization(deu_eng[:, 0])\n    ","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eng_vocab_size = len(eng_tokenizer.word_index) + 1\n\neng_length = 8","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eng_vocab_size","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"6352"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"deu_tokenizer = tokenization(deu_eng[:, 1])\ndeu_vocab_size = len(deu_tokenizer.word_index) + 1\n","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deu_vocab_size","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"10678"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"eng_length = 8\ndeu_length=8","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_sequences(tokenizer, length, lines):\n         # integer encode sequences\n         seq = tokenizer.texts_to_sequences(lines)\n         # pad sequences with 0 values\n         seq = pad_sequences(seq, maxlen=length, padding='post')\n         return seq","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain,test=train_test_split(deu_eng,test_size=0.2,random_state=12)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"(40000, 2)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\ntrainY = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n\n\ntestX = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\ntestY = encode_sequences(deu_tokenizer, deu_length, test[:, 1])","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n      model = Sequential()\n      model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n      model.add(LSTM(units))\n      model.add(RepeatVector(out_timesteps))\n      model.add(LSTM(units, return_sequences=True))\n      model.add(Dense(out_vocab, activation='softmax'))\n      return model","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = define_model(eng_vocab_size, deu_vocab_size, eng_length, deu_length, 512)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rms = optimizers.RMSprop(lr=0.001)\nmodel.compile(optimizer=rms, loss='sparse_categorical_crossentropy')","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'model.h1.24_jan_19'\ncheckpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n\n\nhistory = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n                    epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], \n                    verbose=1)","execution_count":27,"outputs":[{"output_type":"stream","text":"Train on 32000 samples, validate on 8000 samples\nEpoch 1/30\n32000/32000 [==============================] - 9s 283us/step - loss: 4.0033 - val_loss: 3.3957\n\nEpoch 00001: val_loss improved from inf to 3.39574, saving model to model.h1.24_jan_19\nEpoch 2/30\n32000/32000 [==============================] - 6s 186us/step - loss: 3.2585 - val_loss: 3.2243\n\nEpoch 00002: val_loss improved from 3.39574 to 3.22432, saving model to model.h1.24_jan_19\nEpoch 3/30\n32000/32000 [==============================] - 6s 185us/step - loss: 3.0432 - val_loss: 3.0829\n\nEpoch 00003: val_loss improved from 3.22432 to 3.08295, saving model to model.h1.24_jan_19\nEpoch 4/30\n32000/32000 [==============================] - 6s 185us/step - loss: 2.8885 - val_loss: 2.9441\n\nEpoch 00004: val_loss improved from 3.08295 to 2.94408, saving model to model.h1.24_jan_19\nEpoch 5/30\n32000/32000 [==============================] - 6s 185us/step - loss: 2.7725 - val_loss: 2.8520\n\nEpoch 00005: val_loss improved from 2.94408 to 2.85199, saving model to model.h1.24_jan_19\nEpoch 6/30\n32000/32000 [==============================] - 6s 182us/step - loss: 2.6701 - val_loss: 2.7831\n\nEpoch 00006: val_loss improved from 2.85199 to 2.78314, saving model to model.h1.24_jan_19\nEpoch 7/30\n32000/32000 [==============================] - 6s 185us/step - loss: 2.5715 - val_loss: 2.7160\n\nEpoch 00007: val_loss improved from 2.78314 to 2.71597, saving model to model.h1.24_jan_19\nEpoch 8/30\n32000/32000 [==============================] - 6s 191us/step - loss: 2.4742 - val_loss: 2.6524\n\nEpoch 00008: val_loss improved from 2.71597 to 2.65235, saving model to model.h1.24_jan_19\nEpoch 9/30\n32000/32000 [==============================] - 6s 184us/step - loss: 2.3735 - val_loss: 2.5859\n\nEpoch 00009: val_loss improved from 2.65235 to 2.58586, saving model to model.h1.24_jan_19\nEpoch 10/30\n32000/32000 [==============================] - 6s 183us/step - loss: 2.2807 - val_loss: 2.5199\n\nEpoch 00010: val_loss improved from 2.58586 to 2.51986, saving model to model.h1.24_jan_19\nEpoch 11/30\n32000/32000 [==============================] - 6s 182us/step - loss: 2.1857 - val_loss: 2.4550\n\nEpoch 00011: val_loss improved from 2.51986 to 2.45498, saving model to model.h1.24_jan_19\nEpoch 12/30\n32000/32000 [==============================] - 6s 184us/step - loss: 2.0936 - val_loss: 2.3688\n\nEpoch 00012: val_loss improved from 2.45498 to 2.36876, saving model to model.h1.24_jan_19\nEpoch 13/30\n32000/32000 [==============================] - 6s 183us/step - loss: 2.0010 - val_loss: 2.3169\n\nEpoch 00013: val_loss improved from 2.36876 to 2.31685, saving model to model.h1.24_jan_19\nEpoch 14/30\n32000/32000 [==============================] - 6s 181us/step - loss: 1.9111 - val_loss: 2.2663\n\nEpoch 00014: val_loss improved from 2.31685 to 2.26634, saving model to model.h1.24_jan_19\nEpoch 15/30\n32000/32000 [==============================] - 6s 183us/step - loss: 1.8230 - val_loss: 2.2080\n\nEpoch 00015: val_loss improved from 2.26634 to 2.20799, saving model to model.h1.24_jan_19\nEpoch 16/30\n32000/32000 [==============================] - 6s 183us/step - loss: 1.7374 - val_loss: 2.1722\n\nEpoch 00016: val_loss improved from 2.20799 to 2.17220, saving model to model.h1.24_jan_19\nEpoch 17/30\n32000/32000 [==============================] - 6s 182us/step - loss: 1.6548 - val_loss: 2.1092\n\nEpoch 00017: val_loss improved from 2.17220 to 2.10919, saving model to model.h1.24_jan_19\nEpoch 18/30\n32000/32000 [==============================] - 6s 183us/step - loss: 1.5724 - val_loss: 2.0654\n\nEpoch 00018: val_loss improved from 2.10919 to 2.06543, saving model to model.h1.24_jan_19\nEpoch 19/30\n32000/32000 [==============================] - 6s 184us/step - loss: 1.4964 - val_loss: 2.0175\n\nEpoch 00019: val_loss improved from 2.06543 to 2.01754, saving model to model.h1.24_jan_19\nEpoch 20/30\n32000/32000 [==============================] - 6s 184us/step - loss: 1.4212 - val_loss: 1.9715\n\nEpoch 00020: val_loss improved from 2.01754 to 1.97153, saving model to model.h1.24_jan_19\nEpoch 21/30\n32000/32000 [==============================] - 6s 186us/step - loss: 1.3508 - val_loss: 1.9505\n\nEpoch 00021: val_loss improved from 1.97153 to 1.95052, saving model to model.h1.24_jan_19\nEpoch 22/30\n32000/32000 [==============================] - 6s 185us/step - loss: 1.2820 - val_loss: 1.9064\n\nEpoch 00022: val_loss improved from 1.95052 to 1.90645, saving model to model.h1.24_jan_19\nEpoch 23/30\n32000/32000 [==============================] - 6s 184us/step - loss: 1.2171 - val_loss: 1.8846\n\nEpoch 00023: val_loss improved from 1.90645 to 1.88459, saving model to model.h1.24_jan_19\nEpoch 24/30\n32000/32000 [==============================] - 6s 185us/step - loss: 1.1551 - val_loss: 1.8615\n\nEpoch 00024: val_loss improved from 1.88459 to 1.86153, saving model to model.h1.24_jan_19\nEpoch 25/30\n32000/32000 [==============================] - 6s 183us/step - loss: 1.0944 - val_loss: 1.8295\n\nEpoch 00025: val_loss improved from 1.86153 to 1.82955, saving model to model.h1.24_jan_19\nEpoch 26/30\n32000/32000 [==============================] - 6s 182us/step - loss: 1.0357 - val_loss: 1.8121\n\nEpoch 00026: val_loss improved from 1.82955 to 1.81212, saving model to model.h1.24_jan_19\nEpoch 27/30\n32000/32000 [==============================] - 6s 184us/step - loss: 0.9833 - val_loss: 1.7982\n\nEpoch 00027: val_loss improved from 1.81212 to 1.79824, saving model to model.h1.24_jan_19\nEpoch 28/30\n32000/32000 [==============================] - 6s 186us/step - loss: 0.9291 - val_loss: 1.7874\n\nEpoch 00028: val_loss improved from 1.79824 to 1.78739, saving model to model.h1.24_jan_19\nEpoch 29/30\n32000/32000 [==============================] - 6s 181us/step - loss: 0.8795 - val_loss: 1.7659\n\nEpoch 00029: val_loss improved from 1.78739 to 1.76589, saving model to model.h1.24_jan_19\nEpoch 30/30\n32000/32000 [==============================] - 6s 182us/step - loss: 0.8325 - val_loss: 1.7526\n\nEpoch 00030: val_loss improved from 1.76589 to 1.75263, saving model to model.h1.24_jan_19\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_model('model.h1.24_jan_19')\npreds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_word(n, tokenizer):\n      for word, index in tokenizer.word_index.items():\n          if index == n:\n              return word\n      return None","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_text = []\nfor i in preds:\n       temp = []\n       for j in range(len(i)):\n            t = get_word(i[j], deu_tokenizer)\n            if j > 0:\n                if (t == get_word(i[j-1], deu_tokenizer)) or (t == None):\n                     temp.append('')\n                else:\n                     temp.append(t)\n            else:\n                   if(t == None):\n                          temp.append('')\n                   else:\n                          temp.append(t) \n\n       preds_text.append(' '.join(temp))","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = pd.DataFrame({'actual' : test[:,1], 'predicted' : preds_text})","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df.head(15)","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"                                 actual                     predicted\n0                  er wollte reich sein      er wollte reich sein    \n1                         ich liebe tom            ich liebe tom     \n2            lasst uns nach hause gehen  lass uns nach hause gehen   \n3         ich fahre für mein leben gern             ich mag sehr     \n4               das ist mein wörterbuch   das ist mein wörterbuch    \n5                hallo tom guten morgen        hallo tom hierher     \n6              warum ist sie so beliebt           warum ist es so    \n7            ich zeige euch mein zimmer  ich zeige dir mein zimmer   \n8                   hat tom verschlafen        hat tom adoptiert     \n9   leiste nur weiterhin so gute arbeit              mach die zu     \n10              was hat sich zugetragen                 was ist      \n11                      tom ist schwach          tom ist schwach     \n12                 bring tom nach hause             geh tom nach     \n13               die schule ist zu ende      die fenster ist leer    \n14                  es ist zappenduster       es ist stockdunkel     ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>actual</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>er wollte reich sein</td>\n      <td>er wollte reich sein</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ich liebe tom</td>\n      <td>ich liebe tom</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>lasst uns nach hause gehen</td>\n      <td>lass uns nach hause gehen</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ich fahre für mein leben gern</td>\n      <td>ich mag sehr</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>das ist mein wörterbuch</td>\n      <td>das ist mein wörterbuch</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>hallo tom guten morgen</td>\n      <td>hallo tom hierher</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>warum ist sie so beliebt</td>\n      <td>warum ist es so</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ich zeige euch mein zimmer</td>\n      <td>ich zeige dir mein zimmer</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>hat tom verschlafen</td>\n      <td>hat tom adoptiert</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>leiste nur weiterhin so gute arbeit</td>\n      <td>mach die zu</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>was hat sich zugetragen</td>\n      <td>was ist</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>tom ist schwach</td>\n      <td>tom ist schwach</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>bring tom nach hause</td>\n      <td>geh tom nach</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>die schule ist zu ende</td>\n      <td>die fenster ist leer</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>es ist zappenduster</td>\n      <td>es ist stockdunkel</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}